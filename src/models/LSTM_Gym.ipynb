{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnv3fQIwOG7d",
        "outputId": "e1c61fe2-e366-498d-af28-eff97c87512f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.8 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xurHywv7545N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91467a4d-a84c-4356-ddfe-048a9c7af7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuWQBtYw44xZ"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6BpI_eT4-vy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ION8DfLu5CHt"
      },
      "source": [
        "##Extracting Featurse from Mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iTS-jiITiKM"
      },
      "outputs": [],
      "source": [
        "parent_dir = '/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data'\n",
        "excel_path = '/content/drive/MyDrive/Anit/Gym_Posture_Data/candidates list.xlsx'\n",
        "\n",
        "df = pd.read_excel(excel_path)\n",
        "vid_names = df['VidName'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=df['Label'].to_list()\n",
        "print(labels)\n",
        "\n",
        "print('zeros',labels.count(0))\n",
        "print('ones',labels.count(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzG8kmtKsFzB",
        "outputId": "22772f2d-73e4-40a1-967d-83b6534d8bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "zeros 25\n",
            "ones 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFw6hydwPEDg",
        "outputId": "a173f7fd-cac4-47c9-8976-4d3ef1bced83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(vid_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "OtDtGOZhWKNB",
        "outputId": "769464ea-26c0-40db-a20a-e02f91165d0c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1647de4f0456>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Anit/Gym_Posture_Data/Extracted_Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Anit/Gym_Posture_Data/Extracted_Features'"
          ]
        }
      ],
      "source": [
        "os.chdir(f'/content/drive/MyDrive/{}/Gym_Posture_Data/Extracted_Features')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMoEtK_NW__u",
        "outputId": "33b2d7f6-5754-49db-eee0-7867667a1481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/alli1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/alli2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/alli3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anan1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anan2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anan3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anit1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anit2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anit3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/ank1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/ank2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/ank3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anu1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anu2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/anu3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/arvind1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/arvind2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/arvind3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/bhave1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/bhave2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/bhave3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/chi1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/chi2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/chi3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/cos1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/cos2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/cos3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/daga1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/daga2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/daga3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/man1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/man2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/man3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/mango1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/mango2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/mango3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/minku1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/minku2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/minku3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/nik1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/nik2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/nik3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/par1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/par2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/par3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/peher1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/peher2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/peher3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sahu1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sahu2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sahu3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/shashank1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/shashank2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/shashank3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sub1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sub2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/sub3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/tj1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/tj2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/tlp1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/tlp2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/tlp3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/vik1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/vik2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/vik3.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/y1.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/y2.mov\n",
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/gym clean data/y3.mov\n"
          ]
        }
      ],
      "source": [
        "# Iterate through video names\n",
        "for vid_name in vid_names:\n",
        "    test_video = os.path.join(parent_dir, vid_name)\n",
        "\n",
        "    print(test_video)\n",
        "    # Initialize MediaPipe Pose module\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose()\n",
        "\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(test_video)\n",
        "\n",
        "    landmarks_data = []\n",
        "\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to RGB format for MediaPipe\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect poses in the frame\n",
        "        results = pose.process(frame_rgb)\n",
        "\n",
        "        if results.pose_landmarks is not None:\n",
        "            landmarks = []\n",
        "            for landmark in results.pose_landmarks.landmark:\n",
        "                landmarks.append((landmark.x, landmark.y, landmark.z))\n",
        "\n",
        "            landmarks_data.append(landmarks)\n",
        "\n",
        "        # Exit the video by pressing 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    video_capture.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    # Convert landmarks data to a NumPy array\n",
        "    landmarks_array = np.array(landmarks_data)\n",
        "\n",
        "    # Construct the file name including the video name\n",
        "    save_file_name = f'{vid_name}_landmarks.npy'\n",
        "\n",
        "    # Save the landmarks data to a NumPy file\n",
        "    np.save(save_file_name, landmarks_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking the Files which have zero shape"
      ],
      "metadata": {
        "id": "UUPw4QxmjevE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Anit/Gym_Posture_Data/Extracted_Features'\n",
        "list_npy = os.listdir(folder_path)\n",
        "\n",
        "for idx, file_npy in enumerate(list_npy):\n",
        "    file_path = os.path.join(folder_path, file_npy)\n",
        "    file_loaded = np.load(file_path)\n",
        "    if file_loaded.shape == (0,):\n",
        "        print(f\"File at index {idx} has a shape of (0,): {file_npy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IRnG5W-i7HK",
        "outputId": "1176bff2-0c94-4380-abf2-93dfaa436352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File at index 2 has a shape of (0,): alli3.mov_landmarks.npy\n",
            "File at index 23 has a shape of (0,): chi3.mov_landmarks.npy\n",
            "File at index 35 has a shape of (0,): mango3.mov_landmarks.npy\n",
            "File at index 47 has a shape of (0,): peher3.mov_landmarks.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Removing the zero shape file"
      ],
      "metadata": {
        "id": "O-04o6z6jl0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list_npy = [file_npy for file_npy in list_npy if np.load(os.path.join(folder_path, file_npy)).shape != (0,)]\n",
        "print(len(filtered_list_npy))\n",
        "\n",
        "values_list = []\n",
        "\n",
        "for target_value in filtered_list_npy:\n",
        "    target_value = target_value.split('_')[0]\n",
        "    values = df.loc[df['VidName'] == target_value, 'Label'].tolist()\n",
        "    values_list.extend(values)  # Add extracted values to the list\n",
        "\n",
        "print(\"Length of values_list:\", len(values_list))\n",
        "print(\"Length of list_npy:\", len(filtered_list_npy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21rGhf8ijiOD",
        "outputId": "f7a607e0-23b6-4062-e172-02fb1c15aeb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "Length of values_list: 64\n",
            "Length of list_npy: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZjPTAGJtH_d",
        "outputId": "a9ae70d0-6b00-41b9-c8ca-53be035304d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alli1.mov_landmarks.npy',\n",
              " 'alli2.mov_landmarks.npy',\n",
              " 'anan1.mov_landmarks.npy',\n",
              " 'anan2.mov_landmarks.npy',\n",
              " 'anan3.mov_landmarks.npy',\n",
              " 'anit1.mov_landmarks.npy',\n",
              " 'anit2.mov_landmarks.npy',\n",
              " 'anit3.mov_landmarks.npy',\n",
              " 'ank1.mov_landmarks.npy',\n",
              " 'ank2.mov_landmarks.npy',\n",
              " 'ank3.mov_landmarks.npy',\n",
              " 'anu1.mov_landmarks.npy',\n",
              " 'anu2.mov_landmarks.npy',\n",
              " 'anu3.mov_landmarks.npy',\n",
              " 'arvind1.mov_landmarks.npy',\n",
              " 'arvind2.mov_landmarks.npy',\n",
              " 'arvind3.mov_landmarks.npy',\n",
              " 'bhave1.mov_landmarks.npy',\n",
              " 'bhave2.mov_landmarks.npy',\n",
              " 'bhave3.mov_landmarks.npy',\n",
              " 'chi1.mov_landmarks.npy',\n",
              " 'chi2.mov_landmarks.npy',\n",
              " 'cos1.mov_landmarks.npy',\n",
              " 'cos2.mov_landmarks.npy',\n",
              " 'cos3.mov_landmarks.npy',\n",
              " 'daga1.mov_landmarks.npy',\n",
              " 'daga2.mov_landmarks.npy',\n",
              " 'daga3.mov_landmarks.npy',\n",
              " 'man1.mov_landmarks.npy',\n",
              " 'man2.mov_landmarks.npy',\n",
              " 'man3.mov_landmarks.npy',\n",
              " 'mango1.mov_landmarks.npy',\n",
              " 'mango2.mov_landmarks.npy',\n",
              " 'minku1.mov_landmarks.npy',\n",
              " 'minku2.mov_landmarks.npy',\n",
              " 'minku3.mov_landmarks.npy',\n",
              " 'nik1.mov_landmarks.npy',\n",
              " 'nik2.mov_landmarks.npy',\n",
              " 'nik3.mov_landmarks.npy',\n",
              " 'par1.mov_landmarks.npy',\n",
              " 'par2.mov_landmarks.npy',\n",
              " 'par3.mov_landmarks.npy',\n",
              " 'peher1.mov_landmarks.npy',\n",
              " 'peher2.mov_landmarks.npy',\n",
              " 'sahu1.mov_landmarks.npy',\n",
              " 'sahu2.mov_landmarks.npy',\n",
              " 'sahu3.mov_landmarks.npy',\n",
              " 'shashank1.mov_landmarks.npy',\n",
              " 'shashank2.mov_landmarks.npy',\n",
              " 'shashank3.mov_landmarks.npy',\n",
              " 'sub1.mov_landmarks.npy',\n",
              " 'sub2.mov_landmarks.npy',\n",
              " 'sub3.mov_landmarks.npy',\n",
              " 'tj1.mov_landmarks.npy',\n",
              " 'tj2.mov_landmarks.npy',\n",
              " 'tlp1.mov_landmarks.npy',\n",
              " 'tlp2.mov_landmarks.npy',\n",
              " 'tlp3.mov_landmarks.npy',\n",
              " 'vik1.mov_landmarks.npy',\n",
              " 'vik2.mov_landmarks.npy',\n",
              " 'vik3.mov_landmarks.npy',\n",
              " 'y1.mov_landmarks.npy',\n",
              " 'y2.mov_landmarks.npy',\n",
              " 'y3.mov_landmarks.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new shuffled list\n",
        "shuffled_list = random.sample(filtered_list_npy, len(filtered_list_npy))\n",
        "\n",
        "print(\"Original list:\", filtered_list_npy)\n",
        "print(\"Shuffled list:\", shuffled_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2OW0eJ8vV3l",
        "outputId": "522aeeaa-535c-4eac-df79-ef491c3b9668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original list: ['y2.mov_landmarks.npy', 'sub2.mov_landmarks.npy', 'sahu3.mov_landmarks.npy', 'daga3.mov_landmarks.npy', 'sahu1.mov_landmarks.npy', 'anan1.mov_landmarks.npy', 'vik2.mov_landmarks.npy', 'nik1.mov_landmarks.npy', 'arvind1.mov_landmarks.npy', 'cos3.mov_landmarks.npy', 'nik3.mov_landmarks.npy', 'vik1.mov_landmarks.npy', 'vik3.mov_landmarks.npy', 'anu2.mov_landmarks.npy', 'anan2.mov_landmarks.npy', 'bhave3.mov_landmarks.npy', 'cos2.mov_landmarks.npy', 'anit3.mov_landmarks.npy', 'shashank1.mov_landmarks.npy', 'minku3.mov_landmarks.npy', 'minku2.mov_landmarks.npy', 'man2.mov_landmarks.npy', 'cos1.mov_landmarks.npy', 'arvind2.mov_landmarks.npy', 'shashank2.mov_landmarks.npy', 'par3.mov_landmarks.npy', 'bhave1.mov_landmarks.npy', 'man1.mov_landmarks.npy', 'tlp1.mov_landmarks.npy', 'sahu2.mov_landmarks.npy', 'chi1.mov_landmarks.npy', 'sub3.mov_landmarks.npy', 'alli1.mov_landmarks.npy', 'sub1.mov_landmarks.npy', 'par1.mov_landmarks.npy', 'ank1.mov_landmarks.npy', 'anan3.mov_landmarks.npy', 'man3.mov_landmarks.npy', 'anit2.mov_landmarks.npy', 'anit1.mov_landmarks.npy', 'y1.mov_landmarks.npy', 'bhave2.mov_landmarks.npy', 'daga1.mov_landmarks.npy', 'tlp2.mov_landmarks.npy', 'ank3.mov_landmarks.npy', 'nik2.mov_landmarks.npy', 'mango2.mov_landmarks.npy', 'ank2.mov_landmarks.npy', 'peher2.mov_landmarks.npy', 'tlp3.mov_landmarks.npy', 'arvind3.mov_landmarks.npy', 'mango1.mov_landmarks.npy', 'tj2.mov_landmarks.npy', 'shashank3.mov_landmarks.npy', 'daga2.mov_landmarks.npy', 'peher1.mov_landmarks.npy', 'anu3.mov_landmarks.npy', 'par2.mov_landmarks.npy', 'tj1.mov_landmarks.npy', 'alli2.mov_landmarks.npy', 'minku1.mov_landmarks.npy', 'chi2.mov_landmarks.npy', 'y3.mov_landmarks.npy', 'anu1.mov_landmarks.npy']\n",
            "Shuffled list: ['minku1.mov_landmarks.npy', 'chi2.mov_landmarks.npy', 'arvind3.mov_landmarks.npy', 'sahu2.mov_landmarks.npy', 'y1.mov_landmarks.npy', 'tj1.mov_landmarks.npy', 'ank2.mov_landmarks.npy', 'y3.mov_landmarks.npy', 'sub1.mov_landmarks.npy', 'cos1.mov_landmarks.npy', 'chi1.mov_landmarks.npy', 'ank1.mov_landmarks.npy', 'anit3.mov_landmarks.npy', 'tlp2.mov_landmarks.npy', 'anan1.mov_landmarks.npy', 'cos3.mov_landmarks.npy', 'tlp3.mov_landmarks.npy', 'man1.mov_landmarks.npy', 'y2.mov_landmarks.npy', 'bhave1.mov_landmarks.npy', 'bhave3.mov_landmarks.npy', 'vik3.mov_landmarks.npy', 'shashank2.mov_landmarks.npy', 'anit1.mov_landmarks.npy', 'shashank1.mov_landmarks.npy', 'anit2.mov_landmarks.npy', 'mango1.mov_landmarks.npy', 'daga2.mov_landmarks.npy', 'minku3.mov_landmarks.npy', 'nik3.mov_landmarks.npy', 'cos2.mov_landmarks.npy', 'nik1.mov_landmarks.npy', 'ank3.mov_landmarks.npy', 'par3.mov_landmarks.npy', 'par1.mov_landmarks.npy', 'tlp1.mov_landmarks.npy', 'anu2.mov_landmarks.npy', 'daga3.mov_landmarks.npy', 'man2.mov_landmarks.npy', 'alli1.mov_landmarks.npy', 'anan2.mov_landmarks.npy', 'anu1.mov_landmarks.npy', 'tj2.mov_landmarks.npy', 'minku2.mov_landmarks.npy', 'man3.mov_landmarks.npy', 'arvind1.mov_landmarks.npy', 'vik2.mov_landmarks.npy', 'mango2.mov_landmarks.npy', 'peher2.mov_landmarks.npy', 'daga1.mov_landmarks.npy', 'sahu3.mov_landmarks.npy', 'arvind2.mov_landmarks.npy', 'shashank3.mov_landmarks.npy', 'nik2.mov_landmarks.npy', 'bhave2.mov_landmarks.npy', 'anu3.mov_landmarks.npy', 'sahu1.mov_landmarks.npy', 'alli2.mov_landmarks.npy', 'peher1.mov_landmarks.npy', 'anan3.mov_landmarks.npy', 'par2.mov_landmarks.npy', 'sub2.mov_landmarks.npy', 'vik1.mov_landmarks.npy', 'sub3.mov_landmarks.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_feature_path = '/content/drive/MyDrive/Anit/Gym_Posture_Data/Extracted_Features'\n",
        "\n",
        "\n",
        "avg_arr = []\n",
        "for idx in range(0,64):\n",
        "\n",
        "  file_path = os.path.join(extracted_feature_path,filtered_list_npy[idx])\n",
        "  # print(file_path)\n",
        "\n",
        "  file = np.load(file_path)\n",
        "  # print(file.shape[0])\n",
        "  avg_arr.append(file.shape[0])\n",
        "\n",
        "print(np.max(avg_arr))\n",
        "print(np.min(avg_arr))\n",
        "print(np.mean(avg_arr))\n",
        "print(np.std(avg_arr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiWXq3ElFUUD",
        "outputId": "9cf3a91f-8476-4e3e-8c9e-083f067de92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2197\n",
            "328\n",
            "798.515625\n",
            "350.84220064846727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing the value of landmarks coordinates for a random video and random landmark"
      ],
      "metadata": {
        "id": "WhslzYoTod-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0,64)\n",
        "print('File_index_no:',idx)\n",
        "\n",
        "\n",
        "file_path = os.path.join(extracted_feature_path,filtered_list_npy[idx])\n",
        "\n",
        "# print(file_path)\n",
        "\n",
        "file = np.load(file_path)\n",
        "print(file.shape[0])\n",
        "\n",
        "lnd_idx = np.random.randint(0,33)\n",
        "print('landmark_index:',lnd_idx)\n",
        "\n",
        "\n",
        "for i in range(0,file.shape[0],50):\n",
        "  print(f\"{i}:x-coordinate\",file[i,lnd_idx,0])\n",
        "print('\\n')\n",
        "for i in range(0,file.shape[0],50):\n",
        "  print(f\"{i}:y-coordinate\",file[i,lnd_idx,1])\n",
        "print('\\n')\n",
        "\n",
        "for i in range(0,file.shape[0],50):\n",
        "  print(f\"{i}:z-coordinate\",file[i,lnd_idx,2])\n",
        "print('\\n')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy68l9Qkjmkp",
        "outputId": "447cf69b-58ef-4137-81c0-a2b16b78ff4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File_index_no: 36\n",
            "1634\n",
            "landmark_index: 32\n",
            "0:x-coordinate 0.450382262468338\n",
            "50:x-coordinate 0.44737809896469116\n",
            "100:x-coordinate 0.4482800364494324\n",
            "150:x-coordinate 0.44784078001976013\n",
            "200:x-coordinate 0.4491288363933563\n",
            "250:x-coordinate 0.44849860668182373\n",
            "300:x-coordinate 0.4507908225059509\n",
            "350:x-coordinate 0.44729363918304443\n",
            "400:x-coordinate 0.45188573002815247\n",
            "450:x-coordinate 0.4487418532371521\n",
            "500:x-coordinate 0.4516087472438812\n",
            "550:x-coordinate 0.4481900930404663\n",
            "600:x-coordinate 0.44980141520500183\n",
            "650:x-coordinate 0.44753745198249817\n",
            "700:x-coordinate 0.4508907198905945\n",
            "750:x-coordinate 0.44840580224990845\n",
            "800:x-coordinate 0.4518798291683197\n",
            "850:x-coordinate 0.4474010169506073\n",
            "900:x-coordinate 0.44829851388931274\n",
            "950:x-coordinate 0.4477080702781677\n",
            "1000:x-coordinate 0.44825229048728943\n",
            "1050:x-coordinate 0.4476023316383362\n",
            "1100:x-coordinate 0.44773563742637634\n",
            "1150:x-coordinate 0.44721654057502747\n",
            "1200:x-coordinate 0.4482359290122986\n",
            "1250:x-coordinate 0.45016369223594666\n",
            "1300:x-coordinate 0.44995272159576416\n",
            "1350:x-coordinate 0.4509524405002594\n",
            "1400:x-coordinate 0.4483552575111389\n",
            "1450:x-coordinate 0.4523719847202301\n",
            "1500:x-coordinate 0.44907107949256897\n",
            "1550:x-coordinate 0.45201975107192993\n",
            "1600:x-coordinate 0.44826123118400574\n",
            "\n",
            "\n",
            "0:y-coordinate 0.790346622467041\n",
            "50:y-coordinate 0.7949628233909607\n",
            "100:y-coordinate 0.7947033643722534\n",
            "150:y-coordinate 0.7945385575294495\n",
            "200:y-coordinate 0.7922685742378235\n",
            "250:y-coordinate 0.7934606671333313\n",
            "300:y-coordinate 0.7905161380767822\n",
            "350:y-coordinate 0.793003261089325\n",
            "400:y-coordinate 0.7917739748954773\n",
            "450:y-coordinate 0.792458713054657\n",
            "500:y-coordinate 0.7915288805961609\n",
            "550:y-coordinate 0.7931076884269714\n",
            "600:y-coordinate 0.7924454808235168\n",
            "650:y-coordinate 0.7947127819061279\n",
            "700:y-coordinate 0.7908968329429626\n",
            "750:y-coordinate 0.7934693694114685\n",
            "800:y-coordinate 0.7910954356193542\n",
            "850:y-coordinate 0.7947763800621033\n",
            "900:y-coordinate 0.7916670441627502\n",
            "950:y-coordinate 0.794987678527832\n",
            "1000:y-coordinate 0.7936909794807434\n",
            "1050:y-coordinate 0.7941718697547913\n",
            "1100:y-coordinate 0.7940386533737183\n",
            "1150:y-coordinate 0.7939954996109009\n",
            "1200:y-coordinate 0.7936951518058777\n",
            "1250:y-coordinate 0.7921372056007385\n",
            "1300:y-coordinate 0.7911137342453003\n",
            "1350:y-coordinate 0.7913371324539185\n",
            "1400:y-coordinate 0.7912964224815369\n",
            "1450:y-coordinate 0.7908925414085388\n",
            "1500:y-coordinate 0.7922123074531555\n",
            "1550:y-coordinate 0.788624107837677\n",
            "1600:y-coordinate 0.7918679714202881\n",
            "\n",
            "\n",
            "0:z-coordinate -0.008703518658876419\n",
            "50:z-coordinate -0.06410122662782669\n",
            "100:z-coordinate -0.007263782434165478\n",
            "150:z-coordinate -0.08886397629976273\n",
            "200:z-coordinate 0.0007407483062706888\n",
            "250:z-coordinate -0.12888644635677338\n",
            "300:z-coordinate 0.012156476266682148\n",
            "350:z-coordinate -0.1610719859600067\n",
            "400:z-coordinate 0.005504903849214315\n",
            "450:z-coordinate -0.13522012531757355\n",
            "500:z-coordinate 0.005893352907150984\n",
            "550:z-coordinate -0.14771151542663574\n",
            "600:z-coordinate 0.0032565610017627478\n",
            "650:z-coordinate -0.14664918184280396\n",
            "700:z-coordinate 0.0004218344984110445\n",
            "750:z-coordinate -0.14604146778583527\n",
            "800:z-coordinate 0.007940542884171009\n",
            "850:z-coordinate -0.08439026772975922\n",
            "900:z-coordinate 0.024124065414071083\n",
            "950:z-coordinate -0.06622535735368729\n",
            "1000:z-coordinate 0.01944216713309288\n",
            "1050:z-coordinate -0.026313096284866333\n",
            "1100:z-coordinate 0.022388914600014687\n",
            "1150:z-coordinate -0.06454505026340485\n",
            "1200:z-coordinate -0.07570614665746689\n",
            "1250:z-coordinate 0.00396653963252902\n",
            "1300:z-coordinate -0.08140483498573303\n",
            "1350:z-coordinate 0.007144932169467211\n",
            "1400:z-coordinate -0.12528328597545624\n",
            "1450:z-coordinate -0.003025919198989868\n",
            "1500:z-coordinate -0.11878367513418198\n",
            "1550:z-coordinate 0.0061644320376217365\n",
            "1600:z-coordinate -0.1592814326286316\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting a single .npy file into file of 30 frames"
      ],
      "metadata": {
        "id": "ljVL5BnS_ubM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(values_list)|"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx9wdFziVGFL",
        "outputId": "703abce8-dabc-4a63-c385-c977f8534d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "X = np.empty((0, 30, 33, 3), dtype=np.float32)\n",
        "Y = []\n",
        "\n",
        "for idx, file_name in enumerate(filtered_list_npy):\n",
        "    file_path = os.path.join(extracted_feature_path, file_name)\n",
        "    file = np.load(file_path)\n",
        "    label = values_list[idx]\n",
        "    print(\"label:\", label)\n",
        "\n",
        "    N = file.shape[0]\n",
        "    print(f'no.of frames in file {file_name} is:', N)\n",
        "    print(30 * (N // 30))\n",
        "\n",
        "    num_frames_per_dp = 30\n",
        "    num_groups = (N ) // num_frames_per_dp\n",
        "\n",
        "    augmented_frames = np.zeros((num_groups, num_frames_per_dp))\n",
        "    print(augmented_frames.shape)\n",
        "\n",
        "    for i in range(0, num_groups):\n",
        "        for j in range(0, 30):\n",
        "            augmented_frames[i, j] = i + j * num_groups\n",
        "\n",
        "    print('Shape of augmented frames', augmented_frames.shape)\n",
        "    print(augmented_frames[0])\n",
        "\n",
        "    for grp in augmented_frames:\n",
        "        x = []\n",
        "        for frame in grp:\n",
        "            x.append(file[int(frame)])\n",
        "\n",
        "        X = np.append(X, [x], axis=0)\n",
        "        Y.append(label)\n",
        "\n",
        "\n",
        "# Now X should have the shape (300, 30, 33, 3)\n",
        "print('Shape of X:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjVkP2PcahMg",
        "outputId": "1bc4af67-48dc-4f8e-fb45-17728a9273e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: 1\n",
            "no.of frames in file alli1.mov_landmarks.npy is: 949\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 1\n",
            "no.of frames in file alli2.mov_landmarks.npy is: 941\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 1\n",
            "no.of frames in file anan1.mov_landmarks.npy is: 778\n",
            "750\n",
            "(25, 30)\n",
            "Shape of augmented frames (25, 30)\n",
            "[  0.  25.  50.  75. 100. 125. 150. 175. 200. 225. 250. 275. 300. 325.\n",
            " 350. 375. 400. 425. 450. 475. 500. 525. 550. 575. 600. 625. 650. 675.\n",
            " 700. 725.]\n",
            "label: 1\n",
            "no.of frames in file anan2.mov_landmarks.npy is: 948\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 1\n",
            "no.of frames in file anan3.mov_landmarks.npy is: 571\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 0\n",
            "no.of frames in file anit1.mov_landmarks.npy is: 912\n",
            "900\n",
            "(30, 30)\n",
            "Shape of augmented frames (30, 30)\n",
            "[  0.  30.  60.  90. 120. 150. 180. 210. 240. 270. 300. 330. 360. 390.\n",
            " 420. 450. 480. 510. 540. 570. 600. 630. 660. 690. 720. 750. 780. 810.\n",
            " 840. 870.]\n",
            "label: 0\n",
            "no.of frames in file anit2.mov_landmarks.npy is: 891\n",
            "870\n",
            "(29, 30)\n",
            "Shape of augmented frames (29, 30)\n",
            "[  0.  29.  58.  87. 116. 145. 174. 203. 232. 261. 290. 319. 348. 377.\n",
            " 406. 435. 464. 493. 522. 551. 580. 609. 638. 667. 696. 725. 754. 783.\n",
            " 812. 841.]\n",
            "label: 0\n",
            "no.of frames in file anit3.mov_landmarks.npy is: 817\n",
            "810\n",
            "(27, 30)\n",
            "Shape of augmented frames (27, 30)\n",
            "[  0.  27.  54.  81. 108. 135. 162. 189. 216. 243. 270. 297. 324. 351.\n",
            " 378. 405. 432. 459. 486. 513. 540. 567. 594. 621. 648. 675. 702. 729.\n",
            " 756. 783.]\n",
            "label: 1\n",
            "no.of frames in file ank1.mov_landmarks.npy is: 820\n",
            "810\n",
            "(27, 30)\n",
            "Shape of augmented frames (27, 30)\n",
            "[  0.  27.  54.  81. 108. 135. 162. 189. 216. 243. 270. 297. 324. 351.\n",
            " 378. 405. 432. 459. 486. 513. 540. 567. 594. 621. 648. 675. 702. 729.\n",
            " 756. 783.]\n",
            "label: 1\n",
            "no.of frames in file ank2.mov_landmarks.npy is: 1035\n",
            "1020\n",
            "(34, 30)\n",
            "Shape of augmented frames (34, 30)\n",
            "[  0.  34.  68. 102. 136. 170. 204. 238. 272. 306. 340. 374. 408. 442.\n",
            " 476. 510. 544. 578. 612. 646. 680. 714. 748. 782. 816. 850. 884. 918.\n",
            " 952. 986.]\n",
            "label: 1\n",
            "no.of frames in file ank3.mov_landmarks.npy is: 476\n",
            "450\n",
            "(15, 30)\n",
            "Shape of augmented frames (15, 30)\n",
            "[  0.  15.  30.  45.  60.  75.  90. 105. 120. 135. 150. 165. 180. 195.\n",
            " 210. 225. 240. 255. 270. 285. 300. 315. 330. 345. 360. 375. 390. 405.\n",
            " 420. 435.]\n",
            "label: 0\n",
            "no.of frames in file anu1.mov_landmarks.npy is: 624\n",
            "600\n",
            "(20, 30)\n",
            "Shape of augmented frames (20, 30)\n",
            "[  0.  20.  40.  60.  80. 100. 120. 140. 160. 180. 200. 220. 240. 260.\n",
            " 280. 300. 320. 340. 360. 380. 400. 420. 440. 460. 480. 500. 520. 540.\n",
            " 560. 580.]\n",
            "label: 0\n",
            "no.of frames in file anu2.mov_landmarks.npy is: 574\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 0\n",
            "no.of frames in file anu3.mov_landmarks.npy is: 593\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 1\n",
            "no.of frames in file arvind1.mov_landmarks.npy is: 486\n",
            "480\n",
            "(16, 30)\n",
            "Shape of augmented frames (16, 30)\n",
            "[  0.  16.  32.  48.  64.  80.  96. 112. 128. 144. 160. 176. 192. 208.\n",
            " 224. 240. 256. 272. 288. 304. 320. 336. 352. 368. 384. 400. 416. 432.\n",
            " 448. 464.]\n",
            "label: 1\n",
            "no.of frames in file arvind2.mov_landmarks.npy is: 458\n",
            "450\n",
            "(15, 30)\n",
            "Shape of augmented frames (15, 30)\n",
            "[  0.  15.  30.  45.  60.  75.  90. 105. 120. 135. 150. 165. 180. 195.\n",
            " 210. 225. 240. 255. 270. 285. 300. 315. 330. 345. 360. 375. 390. 405.\n",
            " 420. 435.]\n",
            "label: 1\n",
            "no.of frames in file arvind3.mov_landmarks.npy is: 651\n",
            "630\n",
            "(21, 30)\n",
            "Shape of augmented frames (21, 30)\n",
            "[  0.  21.  42.  63.  84. 105. 126. 147. 168. 189. 210. 231. 252. 273.\n",
            " 294. 315. 336. 357. 378. 399. 420. 441. 462. 483. 504. 525. 546. 567.\n",
            " 588. 609.]\n",
            "label: 1\n",
            "no.of frames in file bhave1.mov_landmarks.npy is: 541\n",
            "540\n",
            "(18, 30)\n",
            "Shape of augmented frames (18, 30)\n",
            "[  0.  18.  36.  54.  72.  90. 108. 126. 144. 162. 180. 198. 216. 234.\n",
            " 252. 270. 288. 306. 324. 342. 360. 378. 396. 414. 432. 450. 468. 486.\n",
            " 504. 522.]\n",
            "label: 1\n",
            "no.of frames in file bhave2.mov_landmarks.npy is: 649\n",
            "630\n",
            "(21, 30)\n",
            "Shape of augmented frames (21, 30)\n",
            "[  0.  21.  42.  63.  84. 105. 126. 147. 168. 189. 210. 231. 252. 273.\n",
            " 294. 315. 336. 357. 378. 399. 420. 441. 462. 483. 504. 525. 546. 567.\n",
            " 588. 609.]\n",
            "label: 1\n",
            "no.of frames in file bhave3.mov_landmarks.npy is: 594\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 1\n",
            "no.of frames in file chi1.mov_landmarks.npy is: 2197\n",
            "2190\n",
            "(73, 30)\n",
            "Shape of augmented frames (73, 30)\n",
            "[   0.   73.  146.  219.  292.  365.  438.  511.  584.  657.  730.  803.\n",
            "  876.  949. 1022. 1095. 1168. 1241. 1314. 1387. 1460. 1533. 1606. 1679.\n",
            " 1752. 1825. 1898. 1971. 2044. 2117.]\n",
            "label: 1\n",
            "no.of frames in file chi2.mov_landmarks.npy is: 1816\n",
            "1800\n",
            "(60, 30)\n",
            "Shape of augmented frames (60, 30)\n",
            "[   0.   60.  120.  180.  240.  300.  360.  420.  480.  540.  600.  660.\n",
            "  720.  780.  840.  900.  960. 1020. 1080. 1140. 1200. 1260. 1320. 1380.\n",
            " 1440. 1500. 1560. 1620. 1680. 1740.]\n",
            "label: 1\n",
            "no.of frames in file cos1.mov_landmarks.npy is: 673\n",
            "660\n",
            "(22, 30)\n",
            "Shape of augmented frames (22, 30)\n",
            "[  0.  22.  44.  66.  88. 110. 132. 154. 176. 198. 220. 242. 264. 286.\n",
            " 308. 330. 352. 374. 396. 418. 440. 462. 484. 506. 528. 550. 572. 594.\n",
            " 616. 638.]\n",
            "label: 1\n",
            "no.of frames in file cos2.mov_landmarks.npy is: 598\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 1\n",
            "no.of frames in file cos3.mov_landmarks.npy is: 620\n",
            "600\n",
            "(20, 30)\n",
            "Shape of augmented frames (20, 30)\n",
            "[  0.  20.  40.  60.  80. 100. 120. 140. 160. 180. 200. 220. 240. 260.\n",
            " 280. 300. 320. 340. 360. 380. 400. 420. 440. 460. 480. 500. 520. 540.\n",
            " 560. 580.]\n",
            "label: 0\n",
            "no.of frames in file daga1.mov_landmarks.npy is: 368\n",
            "360\n",
            "(12, 30)\n",
            "Shape of augmented frames (12, 30)\n",
            "[  0.  12.  24.  36.  48.  60.  72.  84.  96. 108. 120. 132. 144. 156.\n",
            " 168. 180. 192. 204. 216. 228. 240. 252. 264. 276. 288. 300. 312. 324.\n",
            " 336. 348.]\n",
            "label: 0\n",
            "no.of frames in file daga2.mov_landmarks.npy is: 381\n",
            "360\n",
            "(12, 30)\n",
            "Shape of augmented frames (12, 30)\n",
            "[  0.  12.  24.  36.  48.  60.  72.  84.  96. 108. 120. 132. 144. 156.\n",
            " 168. 180. 192. 204. 216. 228. 240. 252. 264. 276. 288. 300. 312. 324.\n",
            " 336. 348.]\n",
            "label: 0\n",
            "no.of frames in file daga3.mov_landmarks.npy is: 418\n",
            "390\n",
            "(13, 30)\n",
            "Shape of augmented frames (13, 30)\n",
            "[  0.  13.  26.  39.  52.  65.  78.  91. 104. 117. 130. 143. 156. 169.\n",
            " 182. 195. 208. 221. 234. 247. 260. 273. 286. 299. 312. 325. 338. 351.\n",
            " 364. 377.]\n",
            "label: 1\n",
            "no.of frames in file man1.mov_landmarks.npy is: 786\n",
            "780\n",
            "(26, 30)\n",
            "Shape of augmented frames (26, 30)\n",
            "[  0.  26.  52.  78. 104. 130. 156. 182. 208. 234. 260. 286. 312. 338.\n",
            " 364. 390. 416. 442. 468. 494. 520. 546. 572. 598. 624. 650. 676. 702.\n",
            " 728. 754.]\n",
            "label: 1\n",
            "no.of frames in file man2.mov_landmarks.npy is: 660\n",
            "660\n",
            "(22, 30)\n",
            "Shape of augmented frames (22, 30)\n",
            "[  0.  22.  44.  66.  88. 110. 132. 154. 176. 198. 220. 242. 264. 286.\n",
            " 308. 330. 352. 374. 396. 418. 440. 462. 484. 506. 528. 550. 572. 594.\n",
            " 616. 638.]\n",
            "label: 1\n",
            "no.of frames in file man3.mov_landmarks.npy is: 1003\n",
            "990\n",
            "(33, 30)\n",
            "Shape of augmented frames (33, 30)\n",
            "[  0.  33.  66.  99. 132. 165. 198. 231. 264. 297. 330. 363. 396. 429.\n",
            " 462. 495. 528. 561. 594. 627. 660. 693. 726. 759. 792. 825. 858. 891.\n",
            " 924. 957.]\n",
            "label: 0\n",
            "no.of frames in file mango1.mov_landmarks.npy is: 917\n",
            "900\n",
            "(30, 30)\n",
            "Shape of augmented frames (30, 30)\n",
            "[  0.  30.  60.  90. 120. 150. 180. 210. 240. 270. 300. 330. 360. 390.\n",
            " 420. 450. 480. 510. 540. 570. 600. 630. 660. 690. 720. 750. 780. 810.\n",
            " 840. 870.]\n",
            "label: 0\n",
            "no.of frames in file mango2.mov_landmarks.npy is: 480\n",
            "480\n",
            "(16, 30)\n",
            "Shape of augmented frames (16, 30)\n",
            "[  0.  16.  32.  48.  64.  80.  96. 112. 128. 144. 160. 176. 192. 208.\n",
            " 224. 240. 256. 272. 288. 304. 320. 336. 352. 368. 384. 400. 416. 432.\n",
            " 448. 464.]\n",
            "label: 1\n",
            "no.of frames in file minku1.mov_landmarks.npy is: 1049\n",
            "1020\n",
            "(34, 30)\n",
            "Shape of augmented frames (34, 30)\n",
            "[  0.  34.  68. 102. 136. 170. 204. 238. 272. 306. 340. 374. 408. 442.\n",
            " 476. 510. 544. 578. 612. 646. 680. 714. 748. 782. 816. 850. 884. 918.\n",
            " 952. 986.]\n",
            "label: 1\n",
            "no.of frames in file minku2.mov_landmarks.npy is: 934\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 1\n",
            "no.of frames in file minku3.mov_landmarks.npy is: 902\n",
            "900\n",
            "(30, 30)\n",
            "Shape of augmented frames (30, 30)\n",
            "[  0.  30.  60.  90. 120. 150. 180. 210. 240. 270. 300. 330. 360. 390.\n",
            " 420. 450. 480. 510. 540. 570. 600. 630. 660. 690. 720. 750. 780. 810.\n",
            " 840. 870.]\n",
            "label: 0\n",
            "no.of frames in file nik1.mov_landmarks.npy is: 1634\n",
            "1620\n",
            "(54, 30)\n",
            "Shape of augmented frames (54, 30)\n",
            "[   0.   54.  108.  162.  216.  270.  324.  378.  432.  486.  540.  594.\n",
            "  648.  702.  756.  810.  864.  918.  972. 1026. 1080. 1134. 1188. 1242.\n",
            " 1296. 1350. 1404. 1458. 1512. 1566.]\n",
            "label: 0\n",
            "no.of frames in file nik2.mov_landmarks.npy is: 1512\n",
            "1500\n",
            "(50, 30)\n",
            "Shape of augmented frames (50, 30)\n",
            "[   0.   50.  100.  150.  200.  250.  300.  350.  400.  450.  500.  550.\n",
            "  600.  650.  700.  750.  800.  850.  900.  950. 1000. 1050. 1100. 1150.\n",
            " 1200. 1250. 1300. 1350. 1400. 1450.]\n",
            "label: 1\n",
            "no.of frames in file nik3.mov_landmarks.npy is: 1509\n",
            "1500\n",
            "(50, 30)\n",
            "Shape of augmented frames (50, 30)\n",
            "[   0.   50.  100.  150.  200.  250.  300.  350.  400.  450.  500.  550.\n",
            "  600.  650.  700.  750.  800.  850.  900.  950. 1000. 1050. 1100. 1150.\n",
            " 1200. 1250. 1300. 1350. 1400. 1450.]\n",
            "label: 1\n",
            "no.of frames in file par1.mov_landmarks.npy is: 335\n",
            "330\n",
            "(11, 30)\n",
            "Shape of augmented frames (11, 30)\n",
            "[  0.  11.  22.  33.  44.  55.  66.  77.  88.  99. 110. 121. 132. 143.\n",
            " 154. 165. 176. 187. 198. 209. 220. 231. 242. 253. 264. 275. 286. 297.\n",
            " 308. 319.]\n",
            "label: 1\n",
            "no.of frames in file par2.mov_landmarks.npy is: 328\n",
            "300\n",
            "(10, 30)\n",
            "Shape of augmented frames (10, 30)\n",
            "[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90. 100. 110. 120. 130.\n",
            " 140. 150. 160. 170. 180. 190. 200. 210. 220. 230. 240. 250. 260. 270.\n",
            " 280. 290.]\n",
            "label: 1\n",
            "no.of frames in file par3.mov_landmarks.npy is: 650\n",
            "630\n",
            "(21, 30)\n",
            "Shape of augmented frames (21, 30)\n",
            "[  0.  21.  42.  63.  84. 105. 126. 147. 168. 189. 210. 231. 252. 273.\n",
            " 294. 315. 336. 357. 378. 399. 420. 441. 462. 483. 504. 525. 546. 567.\n",
            " 588. 609.]\n",
            "label: 0\n",
            "no.of frames in file peher1.mov_landmarks.npy is: 496\n",
            "480\n",
            "(16, 30)\n",
            "Shape of augmented frames (16, 30)\n",
            "[  0.  16.  32.  48.  64.  80.  96. 112. 128. 144. 160. 176. 192. 208.\n",
            " 224. 240. 256. 272. 288. 304. 320. 336. 352. 368. 384. 400. 416. 432.\n",
            " 448. 464.]\n",
            "label: 0\n",
            "no.of frames in file peher2.mov_landmarks.npy is: 522\n",
            "510\n",
            "(17, 30)\n",
            "Shape of augmented frames (17, 30)\n",
            "[  0.  17.  34.  51.  68.  85. 102. 119. 136. 153. 170. 187. 204. 221.\n",
            " 238. 255. 272. 289. 306. 323. 340. 357. 374. 391. 408. 425. 442. 459.\n",
            " 476. 493.]\n",
            "label: 1\n",
            "no.of frames in file sahu1.mov_landmarks.npy is: 995\n",
            "990\n",
            "(33, 30)\n",
            "Shape of augmented frames (33, 30)\n",
            "[  0.  33.  66.  99. 132. 165. 198. 231. 264. 297. 330. 363. 396. 429.\n",
            " 462. 495. 528. 561. 594. 627. 660. 693. 726. 759. 792. 825. 858. 891.\n",
            " 924. 957.]\n",
            "label: 1\n",
            "no.of frames in file sahu2.mov_landmarks.npy is: 964\n",
            "960\n",
            "(32, 30)\n",
            "Shape of augmented frames (32, 30)\n",
            "[  0.  32.  64.  96. 128. 160. 192. 224. 256. 288. 320. 352. 384. 416.\n",
            " 448. 480. 512. 544. 576. 608. 640. 672. 704. 736. 768. 800. 832. 864.\n",
            " 896. 928.]\n",
            "label: 1\n",
            "no.of frames in file sahu3.mov_landmarks.npy is: 467\n",
            "450\n",
            "(15, 30)\n",
            "Shape of augmented frames (15, 30)\n",
            "[  0.  15.  30.  45.  60.  75.  90. 105. 120. 135. 150. 165. 180. 195.\n",
            " 210. 225. 240. 255. 270. 285. 300. 315. 330. 345. 360. 375. 390. 405.\n",
            " 420. 435.]\n",
            "label: 1\n",
            "no.of frames in file shashank1.mov_landmarks.npy is: 991\n",
            "990\n",
            "(33, 30)\n",
            "Shape of augmented frames (33, 30)\n",
            "[  0.  33.  66.  99. 132. 165. 198. 231. 264. 297. 330. 363. 396. 429.\n",
            " 462. 495. 528. 561. 594. 627. 660. 693. 726. 759. 792. 825. 858. 891.\n",
            " 924. 957.]\n",
            "label: 1\n",
            "no.of frames in file shashank2.mov_landmarks.npy is: 774\n",
            "750\n",
            "(25, 30)\n",
            "Shape of augmented frames (25, 30)\n",
            "[  0.  25.  50.  75. 100. 125. 150. 175. 200. 225. 250. 275. 300. 325.\n",
            " 350. 375. 400. 425. 450. 475. 500. 525. 550. 575. 600. 625. 650. 675.\n",
            " 700. 725.]\n",
            "label: 1\n",
            "no.of frames in file shashank3.mov_landmarks.npy is: 936\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 1\n",
            "no.of frames in file sub1.mov_landmarks.npy is: 667\n",
            "660\n",
            "(22, 30)\n",
            "Shape of augmented frames (22, 30)\n",
            "[  0.  22.  44.  66.  88. 110. 132. 154. 176. 198. 220. 242. 264. 286.\n",
            " 308. 330. 352. 374. 396. 418. 440. 462. 484. 506. 528. 550. 572. 594.\n",
            " 616. 638.]\n",
            "label: 1\n",
            "no.of frames in file sub2.mov_landmarks.npy is: 667\n",
            "660\n",
            "(22, 30)\n",
            "Shape of augmented frames (22, 30)\n",
            "[  0.  22.  44.  66.  88. 110. 132. 154. 176. 198. 220. 242. 264. 286.\n",
            " 308. 330. 352. 374. 396. 418. 440. 462. 484. 506. 528. 550. 572. 594.\n",
            " 616. 638.]\n",
            "label: 1\n",
            "no.of frames in file sub3.mov_landmarks.npy is: 546\n",
            "540\n",
            "(18, 30)\n",
            "Shape of augmented frames (18, 30)\n",
            "[  0.  18.  36.  54.  72.  90. 108. 126. 144. 162. 180. 198. 216. 234.\n",
            " 252. 270. 288. 306. 324. 342. 360. 378. 396. 414. 432. 450. 468. 486.\n",
            " 504. 522.]\n",
            "label: 0\n",
            "no.of frames in file tj1.mov_landmarks.npy is: 659\n",
            "630\n",
            "(21, 30)\n",
            "Shape of augmented frames (21, 30)\n",
            "[  0.  21.  42.  63.  84. 105. 126. 147. 168. 189. 210. 231. 252. 273.\n",
            " 294. 315. 336. 357. 378. 399. 420. 441. 462. 483. 504. 525. 546. 567.\n",
            " 588. 609.]\n",
            "label: 0\n",
            "no.of frames in file tj2.mov_landmarks.npy is: 649\n",
            "630\n",
            "(21, 30)\n",
            "Shape of augmented frames (21, 30)\n",
            "[  0.  21.  42.  63.  84. 105. 126. 147. 168. 189. 210. 231. 252. 273.\n",
            " 294. 315. 336. 357. 378. 399. 420. 441. 462. 483. 504. 525. 546. 567.\n",
            " 588. 609.]\n",
            "label: 1\n",
            "no.of frames in file tlp1.mov_landmarks.npy is: 1244\n",
            "1230\n",
            "(41, 30)\n",
            "Shape of augmented frames (41, 30)\n",
            "[   0.   41.   82.  123.  164.  205.  246.  287.  328.  369.  410.  451.\n",
            "  492.  533.  574.  615.  656.  697.  738.  779.  820.  861.  902.  943.\n",
            "  984. 1025. 1066. 1107. 1148. 1189.]\n",
            "label: 1\n",
            "no.of frames in file tlp2.mov_landmarks.npy is: 1166\n",
            "1140\n",
            "(38, 30)\n",
            "Shape of augmented frames (38, 30)\n",
            "[   0.   38.   76.  114.  152.  190.  228.  266.  304.  342.  380.  418.\n",
            "  456.  494.  532.  570.  608.  646.  684.  722.  760.  798.  836.  874.\n",
            "  912.  950.  988. 1026. 1064. 1102.]\n",
            "label: 1\n",
            "no.of frames in file tlp3.mov_landmarks.npy is: 999\n",
            "990\n",
            "(33, 30)\n",
            "Shape of augmented frames (33, 30)\n",
            "[  0.  33.  66.  99. 132. 165. 198. 231. 264. 297. 330. 363. 396. 429.\n",
            " 462. 495. 528. 561. 594. 627. 660. 693. 726. 759. 792. 825. 858. 891.\n",
            " 924. 957.]\n",
            "label: 0\n",
            "no.of frames in file vik1.mov_landmarks.npy is: 718\n",
            "690\n",
            "(23, 30)\n",
            "Shape of augmented frames (23, 30)\n",
            "[  0.  23.  46.  69.  92. 115. 138. 161. 184. 207. 230. 253. 276. 299.\n",
            " 322. 345. 368. 391. 414. 437. 460. 483. 506. 529. 552. 575. 598. 621.\n",
            " 644. 667.]\n",
            "label: 0\n",
            "no.of frames in file vik2.mov_landmarks.npy is: 577\n",
            "570\n",
            "(19, 30)\n",
            "Shape of augmented frames (19, 30)\n",
            "[  0.  19.  38.  57.  76.  95. 114. 133. 152. 171. 190. 209. 228. 247.\n",
            " 266. 285. 304. 323. 342. 361. 380. 399. 418. 437. 456. 475. 494. 513.\n",
            " 532. 551.]\n",
            "label: 0\n",
            "no.of frames in file vik3.mov_landmarks.npy is: 524\n",
            "510\n",
            "(17, 30)\n",
            "Shape of augmented frames (17, 30)\n",
            "[  0.  17.  34.  51.  68.  85. 102. 119. 136. 153. 170. 187. 204. 221.\n",
            " 238. 255. 272. 289. 306. 323. 340. 357. 374. 391. 408. 425. 442. 459.\n",
            " 476. 493.]\n",
            "label: 0\n",
            "no.of frames in file y1.mov_landmarks.npy is: 938\n",
            "930\n",
            "(31, 30)\n",
            "Shape of augmented frames (31, 30)\n",
            "[  0.  31.  62.  93. 124. 155. 186. 217. 248. 279. 310. 341. 372. 403.\n",
            " 434. 465. 496. 527. 558. 589. 620. 651. 682. 713. 744. 775. 806. 837.\n",
            " 868. 899.]\n",
            "label: 0\n",
            "no.of frames in file y2.mov_landmarks.npy is: 755\n",
            "750\n",
            "(25, 30)\n",
            "Shape of augmented frames (25, 30)\n",
            "[  0.  25.  50.  75. 100. 125. 150. 175. 200. 225. 250. 275. 300. 325.\n",
            " 350. 375. 400. 425. 450. 475. 500. 525. 550. 575. 600. 625. 650. 675.\n",
            " 700. 725.]\n",
            "label: 0\n",
            "no.of frames in file y3.mov_landmarks.npy is: 773\n",
            "750\n",
            "(25, 30)\n",
            "Shape of augmented frames (25, 30)\n",
            "[  0.  25.  50.  75. 100. 125. 150. 175. 200. 225. 250. 275. 300. 325.\n",
            " 350. 375. 400. 425. 450. 475. 500. 525. 550. 575. 600. 625. 650. 675.\n",
            " 700. 725.]\n",
            "Shape of X: (1674, 30, 33, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Anit/Gym_Posture_Data/train_test')"
      ],
      "metadata": {
        "id": "mXBV4nequqYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "\n",
        "#Saving the files into X and Y\n",
        "np.save('X.npy', X)\n",
        "np.save('Y.npy', Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvKLSZepwny0",
        "outputId": "3b4b6442-fd07-47ba-ce3a-2e8c0b86fb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Anit/Gym_Posture_Data/train_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index = int(len(Y) * 0.8)\n",
        "\n",
        "X_train=np.empty((0, 30, 33, 3), dtype=np.float32)\n",
        "X_test= np.empty((0, 30, 33, 3), dtype=np.float32)\n",
        "\n",
        "X_train = X[:split_index]\n",
        "Y_train = Y[:split_index]\n",
        "\n",
        "X_test = X[split_index:]\n",
        "Y_test = Y[split_index:]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(len(Y_train))\n",
        "print(X_test.shape)\n",
        "print(len(Y_test))\n",
        "\n",
        "np.save('X_train.npy',X_train)\n",
        "np.save('Y_train.npy',Y_train)\n",
        "np.save('X_test.npy',X_test)\n",
        "np.save('Y_test.npy',Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJcgOZp_ueI0",
        "outputId": "396c68df-5c0c-416b-8a23-4f2982911d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1339, 30, 33, 3)\n",
            "1339\n",
            "(335, 30, 33, 3)\n",
            "335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9wca9gx5Fl6"
      },
      "source": [
        "##Training LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gtOucFFs76f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.load(filtered_list_npy[0]).shape\n",
        "\n",
        "X = []\n",
        "y=values_list\n",
        "\n",
        "for file in filtered_list_npy:\n",
        "    X.append(np.load(file))\n"
      ],
      "metadata": {
        "id": "qoOCo9TjkmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "\n",
        "# Define your LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMModel, self).__init()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 33\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_classes = 2\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "JqHXH8ZKnHBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NumPy arrays to lists of tensors\n",
        "X_tensors = [torch.tensor(x, dtype=torch.float32) for x in X]\n",
        "y_tensors = [torch.tensor(label, dtype=torch.long) for label in y]\n",
        "\n",
        "# Get the sequence lengths\n",
        "sequence_lengths = [x_tensor.shape[0] for x_tensor in X_tensors]\n",
        "\n",
        "# Sort tensors by sequence length (descending order)\n",
        "sorted_indices = sorted(range(len(sequence_lengths)), key=lambda i: -sequence_lengths[i])\n",
        "X_tensors = [X_tensors[i] for i in sorted_indices]\n",
        "y_tensors = [y_tensors[i] for i in sorted_indices]\n",
        "sequence_lengths = [sequence_lengths[i] for i in sorted_indices]\n",
        "\n",
        "# Create packed sequences\n",
        "X_packed = pack_padded_sequence(torch.stack(X_tensors), sequence_lengths, batch_first=True)\n",
        "y_packed = torch.stack(y_tensors)\n",
        "\n",
        "# Define a new dataset with packed sequences\n",
        "dataset = TensorDataset(X_packed, y_packed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "3eqKW9aHsQoP",
        "outputId": "297e880d-39e1-4d35-fa1c-6e2601ac3d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5d210d98f80c>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Pad sequences to the maximum length (using zero-padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [949, 1281, 3] at entry 0 and [941, 1289, 3] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_size = int(0.6 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop with model checkpointing\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "model_checkpoint_path = 'best_model.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "          f'Training Loss: {average_train_loss:.4f}, '\n",
        "          f'Validation Loss: {average_val_loss:.4f}')\n",
        "\n",
        "    # Save the model if the validation loss is improved\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        torch.save(model.state_dict(), model_checkpoint_path)\n",
        "        print(\"Model saved\")\n",
        "\n",
        "# Load the best model for testing\n",
        "best_model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n",
        "best_model.load_state_dict(torch.load(model_checkpoint_path))\n",
        "best_model.to(device)\n",
        "\n",
        "# Initialize lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = best_model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate the F1-score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "print(f'F1-score on the test set: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "DO8UfXi4pNql",
        "outputId": "5c476269-335b-458c-ea5c-f73d7b213424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-cae353b69fba>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Split the data into training, validation, and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Vishal dekh paa rha hai kya\n",
        "\n",
        "## Ha bhai"
      ],
      "metadata": {
        "id": "T-bFvMx9p-Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x64v-0II1VWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}