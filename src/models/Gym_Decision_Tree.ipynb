{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n"
      ],
      "metadata": {
        "id": "Fwb6m7cIyQgG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/MyDrive/Anit/Gym_Posture_Data/train_test'\n",
        "\n",
        "X_train = np.load(dir + '/X_train.npy')\n",
        "Y_train = np.load(dir + '/Y_train.npy')\n",
        "\n",
        "X_test = np.load(dir + '/X_test.npy')\n",
        "Y_test = np.load(dir + '/Y_test.npy')\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMzxpF0MzW5o",
        "outputId": "96ed0d3b-c726-417e-f368-c3a33b05ca0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1339, 30, 33, 3)\n",
            "(1339,)\n",
            "(335, 30, 33, 3)\n",
            "(335,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree Model"
      ],
      "metadata": {
        "id": "nDp7O0Dy3ObH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tGKhb1ZoyJNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a8de7b-2632-4ad0-8bd4-a7df42a91a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.61\n",
            "Confusion Matrix:\n",
            " [[123  59]\n",
            " [ 73  80]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.68      0.65       182\n",
            "           1       0.58      0.52      0.55       153\n",
            "\n",
            "    accuracy                           0.61       335\n",
            "   macro avg       0.60      0.60      0.60       335\n",
            "weighted avg       0.60      0.61      0.60       335\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Create a decision tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train_reshaped, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = clf.predict(X_test_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "classification_rep = classification_report(Y_test, Y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uSgQT0NW1kB",
        "outputId": "be5743b6-a819-45b7-c72b-2e9b649a85bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1339, 2970)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn import tree\n",
        "\n",
        "# Get the feature names from your reshaped data\n",
        "feature_names = [f'feature_{i}' for i in range(X_train_reshaped.shape[1])]\n",
        "\n",
        "# Print the decision tree model summary\n",
        "tree_summary = tree.export_text(clf, feature_names=feature_names)\n",
        "print(\"Decision Tree Summary:\\n\", tree_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP29u9_pSXIz",
        "outputId": "27f62b6a-c9c6-4942-a53a-22b90501d539"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Summary:\n",
            " |--- feature_294 <= 0.44\n",
            "|   |--- feature_1545 <= 0.44\n",
            "|   |   |--- class: 1\n",
            "|   |--- feature_1545 >  0.44\n",
            "|   |   |--- class: 0\n",
            "|--- feature_294 >  0.44\n",
            "|   |--- feature_1164 <= 0.54\n",
            "|   |   |--- feature_137 <= 0.00\n",
            "|   |   |   |--- feature_67 <= 0.44\n",
            "|   |   |   |   |--- feature_559 <= 0.14\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_559 >  0.14\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- feature_67 >  0.44\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- feature_137 >  0.00\n",
            "|   |   |   |--- feature_1632 <= 0.44\n",
            "|   |   |   |   |--- feature_531 <= 0.48\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_531 >  0.48\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- feature_1632 >  0.44\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |--- feature_1164 >  0.54\n",
            "|   |   |--- feature_175 <= 0.53\n",
            "|   |   |   |--- feature_436 <= 0.27\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- feature_436 >  0.27\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- feature_175 >  0.53\n",
            "|   |   |   |--- feature_76 <= 0.64\n",
            "|   |   |   |   |--- feature_2102 <= 0.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_2102 >  0.00\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- feature_76 >  0.64\n",
            "|   |   |   |   |--- class: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest Model"
      ],
      "metadata": {
        "id": "v_Z9niOX3Qq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_clf.fit(X_train_reshaped, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred_rf = rf_clf.predict(X_test_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(Y_test, Y_pred_rf)\n",
        "conf_matrix_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
        "classification_rep_rf = classification_report(Y_test, Y_pred_rf)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
        "print(\"Random Forest Confusion Matrix:\\n\", conf_matrix_rf)\n",
        "print(\"Random Forest Classification Report:\\n\", classification_rep_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1fHCax_0vj4",
        "outputId": "8e278c58-37df-4289-d5f7-8cd5938e8260"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.40\n",
            "Random Forest Confusion Matrix:\n",
            " [[ 49 133]\n",
            " [ 68  85]]\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.27      0.33       182\n",
            "           1       0.39      0.56      0.46       153\n",
            "\n",
            "    accuracy                           0.40       335\n",
            "   macro avg       0.40      0.41      0.39       335\n",
            "weighted avg       0.41      0.40      0.39       335\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM Classifier"
      ],
      "metadata": {
        "id": "jdoKEfvW3UqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an SVM classifier\n",
        "svm_clf = SVC(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_clf.fit(X_train_reshaped, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred_svm = svm_clf.predict(X_test_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svm = accuracy_score(Y_test, Y_pred_svm)\n",
        "conf_matrix_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
        "classification_rep_svm = classification_report(Y_test, Y_pred_svm)\n",
        "\n",
        "# Print the results\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
        "print(\"SVM Confusion Matrix:\\n\", conf_matrix_svm)\n",
        "print(\"SVM Classification Report:\\n\", classification_rep_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWqY5pZG0wNg",
        "outputId": "2de0d4ba-05e2-46a5-c51c-87dab26fed6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.47\n",
            "SVM Confusion Matrix:\n",
            " [[  3 179]\n",
            " [  0 153]]\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.03       182\n",
            "           1       0.46      1.00      0.63       153\n",
            "\n",
            "    accuracy                           0.47       335\n",
            "   macro avg       0.73      0.51      0.33       335\n",
            "weighted avg       0.75      0.47      0.31       335\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost Classifier"
      ],
      "metadata": {
        "id": "KOfIjff43X6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an XGBoost classifier\n",
        "xgb_clf = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_clf.fit(X_train_reshaped, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred_xgb = xgb_clf.predict(X_test_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_xgb = accuracy_score(Y_test, Y_pred_xgb)\n",
        "conf_matrix_xgb = confusion_matrix(Y_test, Y_pred_xgb)\n",
        "classification_rep_xgb = classification_report(Y_test, Y_pred_xgb)\n",
        "\n",
        "# Print the results\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\")\n",
        "print(\"XGBoost Confusion Matrix:\\n\", conf_matrix_xgb)\n",
        "print(\"XGBoost Classification Report:\\n\", classification_rep_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTa_Y5yy2Ur5",
        "outputId": "b2ddb08c-2c0f-4696-fe55-187479c850d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.75\n",
            "XGBoost Confusion Matrix:\n",
            " [[ 97  85]\n",
            " [  0 153]]\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.53      0.70       182\n",
            "           1       0.64      1.00      0.78       153\n",
            "\n",
            "    accuracy                           0.75       335\n",
            "   macro avg       0.82      0.77      0.74       335\n",
            "weighted avg       0.84      0.75      0.74       335\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM Model"
      ],
      "metadata": {
        "id": "lhZqSJFa3d9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape X_train and X_test to have a 2D shape (number_of_samples, sequence_length * features)\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Use label encoder to convert binary labels to 0 and 1\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
        "Y_test_encoded = label_encoder.transform(Y_test)\n",
        "\n",
        "# Reshape Y_train_encoded and Y_test_encoded to have a 2D shape (number_of_samples, 1)\n",
        "Y_train_encoded = Y_train_encoded.reshape(-1, 1)\n",
        "Y_test_encoded = Y_test_encoded.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(np.expand_dims(X_train_reshaped, axis=-1), Y_train_encoded, epochs=30, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(np.expand_dims(X_test_reshaped, axis=-1), Y_test_encoded)[1]\n",
        "print(f\"LSTM Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wTvfjn1w4ZhV",
        "outputId": "d6251815-ab95-4f0c-9c00-81c97c8182c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "34/34 [==============================] - 7s 116ms/step - loss: 0.6286 - accuracy: 0.6909 - val_loss: 0.5055 - val_accuracy: 0.8769\n",
            "Epoch 2/30\n",
            "34/34 [==============================] - 4s 107ms/step - loss: 0.6151 - accuracy: 0.6909 - val_loss: 0.4390 - val_accuracy: 0.8769\n",
            "Epoch 3/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6147 - accuracy: 0.6909 - val_loss: 0.4654 - val_accuracy: 0.8769\n",
            "Epoch 4/30\n",
            "34/34 [==============================] - 3s 78ms/step - loss: 0.6138 - accuracy: 0.6909 - val_loss: 0.4883 - val_accuracy: 0.8769\n",
            "Epoch 5/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6150 - accuracy: 0.6909 - val_loss: 0.4838 - val_accuracy: 0.8769\n",
            "Epoch 6/30\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.6163 - accuracy: 0.6909 - val_loss: 0.4622 - val_accuracy: 0.8769\n",
            "Epoch 7/30\n",
            "34/34 [==============================] - 4s 122ms/step - loss: 0.6142 - accuracy: 0.6909 - val_loss: 0.4577 - val_accuracy: 0.8769\n",
            "Epoch 8/30\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.6122 - accuracy: 0.6909 - val_loss: 0.4766 - val_accuracy: 0.8769\n",
            "Epoch 9/30\n",
            "34/34 [==============================] - 4s 126ms/step - loss: 0.6151 - accuracy: 0.6909 - val_loss: 0.4701 - val_accuracy: 0.8769\n",
            "Epoch 10/30\n",
            "34/34 [==============================] - 4s 112ms/step - loss: 0.6115 - accuracy: 0.6909 - val_loss: 0.4240 - val_accuracy: 0.8769\n",
            "Epoch 11/30\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.6120 - accuracy: 0.6909 - val_loss: 0.4696 - val_accuracy: 0.8769\n",
            "Epoch 12/30\n",
            "34/34 [==============================] - 3s 80ms/step - loss: 0.6178 - accuracy: 0.6909 - val_loss: 0.4518 - val_accuracy: 0.8769\n",
            "Epoch 13/30\n",
            "34/34 [==============================] - 3s 78ms/step - loss: 0.6110 - accuracy: 0.6909 - val_loss: 0.4376 - val_accuracy: 0.8769\n",
            "Epoch 14/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6129 - accuracy: 0.6909 - val_loss: 0.4824 - val_accuracy: 0.8769\n",
            "Epoch 15/30\n",
            "34/34 [==============================] - 4s 105ms/step - loss: 0.6144 - accuracy: 0.6909 - val_loss: 0.4358 - val_accuracy: 0.8769\n",
            "Epoch 16/30\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.6101 - accuracy: 0.6909 - val_loss: 0.4736 - val_accuracy: 0.8769\n",
            "Epoch 17/30\n",
            "34/34 [==============================] - 3s 80ms/step - loss: 0.6098 - accuracy: 0.6909 - val_loss: 0.4267 - val_accuracy: 0.8769\n",
            "Epoch 18/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6077 - accuracy: 0.6909 - val_loss: 0.4295 - val_accuracy: 0.8769\n",
            "Epoch 19/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6044 - accuracy: 0.6909 - val_loss: 0.5029 - val_accuracy: 0.8769\n",
            "Epoch 20/30\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.6140 - accuracy: 0.6909 - val_loss: 0.4432 - val_accuracy: 0.8769\n",
            "Epoch 21/30\n",
            "34/34 [==============================] - 4s 105ms/step - loss: 0.6055 - accuracy: 0.6909 - val_loss: 0.4465 - val_accuracy: 0.8769\n",
            "Epoch 22/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6175 - accuracy: 0.6909 - val_loss: 0.6074 - val_accuracy: 0.8769\n",
            "Epoch 23/30\n",
            "34/34 [==============================] - 3s 78ms/step - loss: 0.6333 - accuracy: 0.6909 - val_loss: 0.4260 - val_accuracy: 0.8769\n",
            "Epoch 24/30\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.6109 - accuracy: 0.6909 - val_loss: 0.4404 - val_accuracy: 0.8769\n",
            "Epoch 25/30\n",
            "34/34 [==============================] - 3s 88ms/step - loss: 0.6096 - accuracy: 0.6909 - val_loss: 0.4690 - val_accuracy: 0.8769\n",
            "Epoch 26/30\n",
            "34/34 [==============================] - 4s 116ms/step - loss: 0.6109 - accuracy: 0.6909 - val_loss: 0.4133 - val_accuracy: 0.8769\n",
            "Epoch 27/30\n",
            "34/34 [==============================] - 3s 82ms/step - loss: 0.6097 - accuracy: 0.6909 - val_loss: 0.4203 - val_accuracy: 0.8769\n",
            "Epoch 28/30\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.6909"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4892d0d600a9>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1830\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                         )\n\u001b[0;32m-> 1832\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1833\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2270\u001b[0m                         ):\n\u001b[1;32m   2271\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2273\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4078\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4079\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4081\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    877\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize input data\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n",
        "X_test_normalized = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n",
        "\n",
        "# Reshape X_train and X_test to have a 3D shape (number_of_samples, sequence_length, features)\n",
        "X_train_reshaped = X_train_normalized.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
        "X_test_reshaped = X_test_normalized.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
        "\n",
        "# Use label encoder to convert binary labels to 0 and 1\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
        "Y_test_encoded = label_encoder.transform(Y_test)\n",
        "\n",
        "# Reshape Y_train_encoded and Y_test_encoded to have a 2D shape (number_of_samples, 1)\n",
        "Y_train_encoded = Y_train_encoded.reshape(-1, 1)\n",
        "Y_test_encoded = Y_test_encoded.reshape(-1, 1)\n",
        "\n",
        "# Define the LSTM model with dropout\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "model.add(Dropout(0.2))  # Add dropout to reduce overfitting\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, Y_train_encoded, epochs=30, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(X_test_reshaped, Y_test_encoded)[1]\n",
        "print(f\"LSTM Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU8Iy2eY4lIB",
        "outputId": "f2451c4a-93d0-4852-ac6c-da4ea148e6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "34/34 [==============================] - 4s 28ms/step - loss: 0.6247 - accuracy: 0.6788 - val_loss: 0.4328 - val_accuracy: 0.8769\n",
            "Epoch 2/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.6909 - val_loss: 0.4470 - val_accuracy: 0.8769\n",
            "Epoch 3/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.6900 - val_loss: 0.4442 - val_accuracy: 0.8769\n",
            "Epoch 4/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.6046 - accuracy: 0.6891 - val_loss: 0.4910 - val_accuracy: 0.8769\n",
            "Epoch 5/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.6816 - val_loss: 0.4462 - val_accuracy: 0.8881\n",
            "Epoch 6/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.6611 - val_loss: 0.2857 - val_accuracy: 0.8657\n",
            "Epoch 7/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5504 - accuracy: 0.6704 - val_loss: 0.4590 - val_accuracy: 0.8769\n",
            "Epoch 8/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5792 - accuracy: 0.6667 - val_loss: 0.4827 - val_accuracy: 0.8769\n",
            "Epoch 9/30\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.6218 - accuracy: 0.6909 - val_loss: 0.4700 - val_accuracy: 0.8769\n",
            "Epoch 10/30\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.6109 - accuracy: 0.6919 - val_loss: 0.4634 - val_accuracy: 0.8769\n",
            "Epoch 11/30\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.6092 - accuracy: 0.6919 - val_loss: 0.4305 - val_accuracy: 0.8769\n",
            "Epoch 12/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.6909 - val_loss: 0.3602 - val_accuracy: 0.8769\n",
            "Epoch 13/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.6807 - val_loss: 0.3847 - val_accuracy: 0.8769\n",
            "Epoch 14/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.6566 - accuracy: 0.6312 - val_loss: 0.4772 - val_accuracy: 0.8769\n",
            "Epoch 15/30\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.6131 - accuracy: 0.6835 - val_loss: 0.4057 - val_accuracy: 0.8769\n",
            "Epoch 16/30\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5990 - accuracy: 0.6863 - val_loss: 0.4939 - val_accuracy: 0.8769\n",
            "Epoch 17/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6881 - val_loss: 0.3916 - val_accuracy: 0.8769\n",
            "Epoch 18/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6648 - val_loss: 0.5440 - val_accuracy: 0.8769\n",
            "Epoch 19/30\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6928 - val_loss: 0.3775 - val_accuracy: 0.8769\n",
            "Epoch 20/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.5968 - accuracy: 0.6863 - val_loss: 0.4059 - val_accuracy: 0.8769\n",
            "Epoch 21/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6807 - val_loss: 0.4344 - val_accuracy: 0.8769\n",
            "Epoch 22/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6355 - accuracy: 0.6900 - val_loss: 0.4648 - val_accuracy: 0.8769\n",
            "Epoch 23/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6242 - accuracy: 0.6863 - val_loss: 0.4502 - val_accuracy: 0.8769\n",
            "Epoch 24/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.6863 - val_loss: 0.4261 - val_accuracy: 0.8769\n",
            "Epoch 25/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5555 - accuracy: 0.6965 - val_loss: 0.2903 - val_accuracy: 0.9366\n",
            "Epoch 26/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.6835 - val_loss: 0.4044 - val_accuracy: 0.8769\n",
            "Epoch 27/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5746 - accuracy: 0.6881 - val_loss: 0.3025 - val_accuracy: 0.8769\n",
            "Epoch 28/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5798 - accuracy: 0.6807 - val_loss: 0.5382 - val_accuracy: 0.8769\n",
            "Epoch 29/30\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.6891 - val_loss: 0.3949 - val_accuracy: 0.8769\n",
            "Epoch 30/30\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.6872 - val_loss: 0.4007 - val_accuracy: 0.8769\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.4567\n",
            "LSTM Accuracy: 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIo1dWTe7BM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}